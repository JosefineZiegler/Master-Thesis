{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4dee5d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gempy as gp\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from gempy.assets import topology as tp\n",
    "from tqdm import tqdm_notebook\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195bb952",
   "metadata": {},
   "source": [
    "## Geometric model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adb761d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_model_1 = pd.read_csv(r'C:\\Users\\Josefine\\OneDrive\\Dokumente\\Masterarbeit\\Model_Notebooks\\Versuch zwei\\Data\\test_sur.csv')\n",
    "x_max=surf_model_1['X'].max()\n",
    "x_min=surf_model_1['X'].min()\n",
    "y_max=surf_model_1['Y'].max()\n",
    "y_min=surf_model_1['Y'].min()\n",
    "z_max=surf_model_1['Z'].max()\n",
    "z_min=surf_model_1['Z'].min()-500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd8dbdc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active grids: ['regular']\n",
      "Fault colors changed. If you do not like this behavior, set change_color to False.\n",
      "Setting kriging parameters to their default values.\n",
      "Compiling theano function...\n",
      "Level of Optimization:  fast_run\n",
      "Device:  cpu\n",
      "Precision:  float64\n",
      "Number of faults:  5\n",
      "Compilation Done!\n",
      "Kriging values: \n",
      "                              values\n",
      "range                  96979.546529\n",
      "$C_o$              223929343.928571\n",
      "drift equations  [3, 3, 3, 3, 3, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Lithology ids \n",
       "  [11.         11.         10.99996567 ...  7.          7.\n",
       "  7.        ] "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_model1 = gp.create_model('Model1')\n",
    "# Importing the data from CSV-files and setting extent and resolution\n",
    "gp.init_data(geo_model1, [x_min, x_max, y_min, y_max, z_min, z_max], [100,100,50],\n",
    "             path_o= r'C:\\Users\\Josefine\\OneDrive\\Dokumente\\Masterarbeit\\Model_Notebooks\\Versuch zwei\\Data\\test_or.csv',\n",
    "             path_i= r'C:\\Users\\Josefine\\OneDrive\\Dokumente\\Masterarbeit\\Model_Notebooks\\Versuch zwei\\Data\\test_sur.csv',\n",
    "             default_values=False)\n",
    "\n",
    "gp.map_stack_to_surfaces(geo_model1,\n",
    "                         {\n",
    "                         \"Fault_1\": ('fault_1'), \n",
    "                          \"Fault_2\": ('fault_2'), \n",
    "                          \"Fault_3\": ('fault_3'), \n",
    "                          \"Fault_4\": ('fault_4'),\n",
    "                          \"Fault_5\": ('fault_5'), \n",
    "                          \"Strat_Series\":(\n",
    "                              'UFM', \n",
    "                              'UMM',\n",
    "                              'LFM', \n",
    "                              'helvetic',\n",
    "                              'mesozoic',\n",
    "                              'basement'\n",
    "                          ),                                \n",
    "                         },remove_unused_series=True)\n",
    "\n",
    "geo_model1.set_is_fault(['Fault_1',\n",
    "                        'Fault_2', \n",
    "                        'Fault_3', \n",
    "                        'Fault_4', \n",
    "                        'Fault_5',\n",
    "                      ],change_color=True)\n",
    "interp_data = gp.set_interpolator(geo_model1,\n",
    "                                 compile_theano=True,\n",
    "                                 theano_optimizer='fast_run', gradient=False,\n",
    "                                 dype='float32')\n",
    "geo_model1.surfaces.colors.change_colors({\n",
    "                                        'UFM':'#F2F542' , \n",
    "                                        'UMM':'#917E11',\n",
    "                                         'LFM':'#CCBD6A',\n",
    "                                          'helvetic': '#6BA0BF',\n",
    "                                          'mesozoic': '#6BA0BF', \n",
    "                                          'basement' : '#6BA0BF'\n",
    "                                       })\n",
    "gp.compute_model(geo_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85682712",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.plot_3d(geo_model1, image=False, show_lith=False, show_data=True, show_results=True, plotter_type='background')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85e0082",
   "metadata": {},
   "source": [
    "## Uncertainty \n",
    "\n",
    "Credits to Elisa Heim and Sofia brisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77a05a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import sys\n",
    "sys.path.append(\"./\")\n",
    "import fishdist as fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6844d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vMF_list(geo_model, kappas, datatype = 'all'):\n",
    "    surfaces_df = geo_model.surfaces.df\n",
    "    orient_df = geo_model.orientations.df\n",
    "    vMF_list=[]\n",
    "    \n",
    "    if datatype == 'faultsonly':\n",
    "        faults = list(surfaces_df[surfaces_df['isFault'] == True].index)\n",
    "        df = orient_df[orient_df.surface.isin(faults)]\n",
    "        \n",
    "    elif datatype == 'lithonly':\n",
    "        notfaults = list(surfaces_df[surfaces_df['isFault'] == False].index)\n",
    "        df = orient_df[orient_df.series.isin(notfaults)]\n",
    "        \n",
    "    elif datatype == 'all':\n",
    "        df = orient_df\n",
    "        \n",
    "    else:\n",
    "        print('nö.')\n",
    "    for e, i in df[['G_x', 'G_y', 'G_z']].iterrows():\n",
    "        a = 0\n",
    "        vMF_list.append(fish.vMF('vMF_' + str(e), mean=i[['G_x', 'G_y', 'G_z']].values, kappa=kappas[a]))\n",
    "        a += 1\n",
    "    return vMF_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a443690",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the different values to be able to make the model virgin again after each uncertainty loop\n",
    "surf_x_1 = geo_model1.surface_points.df['X']\n",
    "surf_y_1 = geo_model1.surface_points.df['Y']\n",
    "surf_z_1 = geo_model1.surface_points.df['Z']\n",
    "\n",
    "or_x = geo_model1.orientations.df['X']\n",
    "or_y = geo_model1.orientations.df['Y']\n",
    "or_z = geo_model1.orientations.df['Z']\n",
    "or_dip = geo_model1.orientations.df['dip']\n",
    "or_azimuth = geo_model1.orientations.df['azimuth']\n",
    "\n",
    "surf_indexes = list(geo_model1.surface_points.df.index)\n",
    "or_indexes = list(geo_model1.orientations.df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "116dcc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the initial dataframe\n",
    "or_1 = geo_model1.orientations.df.copy()\n",
    "\n",
    "# define concentration parameter for input data\n",
    "kappadict_1 = {'fault_1' : 100, 'fault_2' : 100, 'fault_3' : 100, 'fault_4' : 100,\n",
    "               'fault_5' : 100,\n",
    "               'UFM' : 100, 'UMM' : 100, 'LFM' : 100, 'helvetic' : 100, 'mesozoic' : 100}\n",
    "\n",
    "# assign kappa values to the copied dataframe\n",
    "for surface, kappa in kappadict_1.items():\n",
    "    or_1.loc[or_1['surface'] == surface, 'kappa'] = kappa #orientations now has a new column with kappa\n",
    "    \n",
    "kappas = or_1['kappa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16ba067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in this list, a distribution for every orientation data point is stored, we can sample from that later.\n",
    "vMF_list = create_vMF_list(geo_model1, kappas, datatype = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3350b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the model extent\n",
    "max_z = surf_z_1.min() \n",
    "min_z = surf_z_1.max() \n",
    "\n",
    "#from there downwards, uncertainty increases linearly\n",
    "min_uncert = 100\n",
    "max_uncert = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2476305",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6b5cdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define for cleaner code\n",
    "subsurf_x = geo_model1.surface_points.df['X'][geo_model1.surface_points.df['Z']<=500]\n",
    "subsurf_y = geo_model1.surface_points.df['Y'][geo_model1.surface_points.df['Z']<=500]\n",
    "subsurf_z = geo_model1.surface_points.df['Z'][geo_model1.surface_points.df['Z']<=500]\n",
    "\n",
    "surf_x = geo_model1.surface_points.df['X'][geo_model1.surface_points.df['Z']>500]\n",
    "surf_y = geo_model1.surface_points.df['Y'][geo_model1.surface_points.df['Z']>500]\n",
    "surf_z = geo_model1.surface_points.df['Z'][geo_model1.surface_points.df['Z']>500]\n",
    "\n",
    "mask = np.ones(len(geo_model1.orientations.df), dtype = bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451262ab",
   "metadata": {},
   "source": [
    "#### Attempt to establish priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f04de4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# priors: sample from each distribution\n",
    "def evaluate_sigma(iteration,surface_name, depth_points):\n",
    "    \n",
    "    dp_subsurf = depth_points[depth_points <= 500]\n",
    "    dp_surf = depth_points[depth_points > 500]\n",
    "    \n",
    "    depth_uncert_subsurf = np.abs((max_uncert*dp_subsurf[surface_name].dropna())/max_z)\n",
    "    \n",
    "    if surface_name in ['fault_3','fault_4']:\n",
    "        sigma_1 = np.random.normal(0, 2*(depth_uncert_subsurf))\n",
    "        sigma_2 = np.random.normal(0, 2*(depth_uncert_subsurf))\n",
    "        sigma_3 = np.random.normal(0, 3*(depth_uncert_subsurf))\n",
    "        sigma_4 = np.random.uniform(-200, 200)\n",
    "        sigma_5 = np.random.uniform(-200, 200)\n",
    "        sigma_6 = None\n",
    "        sigma_7 = None\n",
    "        sigma_8 = None\n",
    "        sigma_9 = None\n",
    "        sigma_10 = None\n",
    "        sigma_11 = None\n",
    "        \n",
    "    else:\n",
    "        sigma_1 = None\n",
    "        sigma_2 = None\n",
    "        sigma_3 = None\n",
    "        sigma_4 = None\n",
    "        sigma_5 = None\n",
    "        sigma_6 = np.random.normal(0, np.abs(depth_uncert_subsurf))\n",
    "        sigma_7 = np.random.normal(0, np.abs(depth_uncert_subsurf))\n",
    "        sigma_8 = np.random.normal(0, np.abs(1.5*(depth_uncert_subsurf)))\n",
    "        sigma_9 = np.random.uniform(-100, 100)\n",
    "        sigma_10 = np.random.uniform(-100, 100)\n",
    "        sigma_11 = np.random.normal(0, 5)\n",
    "    \n",
    "    return [iteration,sigma_1,sigma_2,sigma_3,sigma_4,sigma_5,sigma_6,sigma_7,sigma_8,sigma_9,sigma_10,sigma_11,surface_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3926e60c",
   "metadata": {},
   "source": [
    "## Add uncertainty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8bdabe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_points = pd.read_csv('depth_points - Copy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "80f917a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 471/471 [15:58:28<00:00, 122.10s/it]\n"
     ]
    }
   ],
   "source": [
    "surfaces_1 = np.unique(geo_model1.surface_points.df['surface'])\n",
    "voxels =100*100*50\n",
    "modify_by_surface = True\n",
    "modify_orientations = True\n",
    "save = True\n",
    "\n",
    "n_iterations = 1000\n",
    "\n",
    "for iteration in tqdm(range(n_iterations)):\n",
    "    #reset model to original\n",
    "    geo_model1.modify_surface_points(surf_indexes, X = surf_x_1, Y = surf_y_1, Z = surf_z_1)\n",
    "    geo_model1.modify_orientations(or_indexes, X = or_x, Y = or_y, Z = or_z, \n",
    "                                       dip = or_dip, azimuth = or_azimuth)\n",
    "    geo_model1.update_to_interpolator()\n",
    "        \n",
    "    if modify_by_surface == True:\n",
    "        sigma_list = []\n",
    "        for surf in surfaces_1:    \n",
    "            if surf in ['fault_3','fault_4']:\n",
    "                sigma_list.append(evaluate_sigma(iteration,surf, depth_points))\n",
    "\n",
    "                subsurf_x[geo_model1.surface_points.df['surface'] == surf] = subsurf_x[geo_model1.surface_points.df['surface'] == surf]  + sigma_list[-1][1]\n",
    "                subsurf_y[geo_model1.surface_points.df['surface'] == surf] = subsurf_y[geo_model1.surface_points.df['surface'] == surf]  + sigma_list[-1][2]\n",
    "\n",
    "                # add uncertainty to subsurface position z (uncertainty increases with depth)\n",
    "                subsurf_z[geo_model1.surface_points.df['surface'] == surf] = subsurf_z[geo_model1.surface_points.df['surface'] == surf]  + sigma_list[-1][3]\n",
    "\n",
    "                # add uncertainty to surface position x,y\n",
    "                surf_x[geo_model1.surface_points.df['surface'] == surf] = surf_x[geo_model1.surface_points.df['surface'] == surf]  + sigma_list[-1][4]\n",
    "                surf_y[geo_model1.surface_points.df['surface'] == surf] = surf_y[geo_model1.surface_points.df['surface'] == surf]  + sigma_list[-1][5]\n",
    "\n",
    "            else:\n",
    "                   \n",
    "                sigma_list.append(evaluate_sigma(iteration,surf, depth_points))\n",
    "\n",
    "                subsurf_x[geo_model1.surface_points.df['surface'] == surf] = subsurf_x[geo_model1.surface_points.df['surface'] == surf]  + sigma_list[-1][6]\n",
    "                subsurf_y[geo_model1.surface_points.df['surface'] == surf] = subsurf_y[geo_model1.surface_points.df['surface'] == surf]  + sigma_list[-1][7]\n",
    "\n",
    "                # add uncertainty to subsurface position z (uncertainty increases with depth)\n",
    "                subsurf_z[geo_model1.surface_points.df['surface'] == surf] = subsurf_z[geo_model1.surface_points.df['surface'] == surf]  + sigma_list[-1][8]\n",
    "\n",
    "                # add uncertainty to surface position x,y\n",
    "                surf_x[geo_model1.surface_points.df['surface'] == surf] = surf_x[geo_model1.surface_points.df['surface'] == surf]  + sigma_list[-1][9]\n",
    "                surf_y[geo_model1.surface_points.df['surface'] == surf] = surf_y[geo_model1.surface_points.df['surface'] == surf]  + sigma_list[-1][10]\n",
    "\n",
    "                # add z uncertainty to surface data\n",
    "                surf_z[geo_model1.surface_points.df['surface'] == surf] = surf_z[geo_model1.surface_points.df['surface'] == surf]  + sigma_list[-1][11]\n",
    "\n",
    "        if modify_orientations == True:\n",
    "            new_orientations = np.vstack(list(map(lambda x : x.sample(num_samples = 1, \n",
    "                                                                      direct_output = True)[0],vMF_list)))\n",
    "            a = fish.vMF()\n",
    "            a.add_orientation_data(new_orientations)\n",
    "\n",
    "            geo_model1.orientations.df.loc[mask, ['G_x', 'G_y', 'G_z']] = new_orientations\n",
    "            geo_model1.orientations.df.loc[mask, 'azmiuth'] = a.samples_azdip[:,0]\n",
    "            geo_model1.orientations.df.loc[mask, 'dip'] = a.samples_azdip[:,1]\n",
    "        \n",
    "        geo_model1.update_to_interpolator()\n",
    "        gp.compute_model(geo_model1)\n",
    "        \n",
    "    if save == True:\n",
    "        np.save('blocks0/1_%04d.npy'%iteration, geo_model1.solutions.block_matrix[0,0:voxels])\n",
    "        np.save('blocks1/1_%04d.npy'%iteration, geo_model1.solutions.block_matrix[1,0:voxels])\n",
    "        np.save('blocks2/1_%04d.npy'%iteration, geo_model1.solutions.block_matrix[2,0:voxels])\n",
    "        np.save('blocks3/1_%04d.npy'%iteration, geo_model1.solutions.block_matrix[3,0:voxels])\n",
    "        np.save('blocks4/1_%04d.npy'%iteration, geo_model1.solutions.block_matrix[4,0:voxels])\n",
    "        np.save('blocks5/1_%04d.npy'%iteration, geo_model1.solutions.block_matrix[5,0:voxels])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4288384d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e25778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0646f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3932538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
